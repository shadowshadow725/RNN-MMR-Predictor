{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cd97a9",
   "metadata": {},
   "source": [
    "# MMR Predictor\n",
    "Predicting MMR of a *League of Legends* match using Recurrent Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "309f19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from typing import Dict, List\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4633ee",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3d459fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_mmr(elo_ratings):\n",
    "    \"\"\"\n",
    "    Calculate the average value of 10 players' ELO ratings.\n",
    "    Return -1 if the avg is out of bounds (0 - 3386)\n",
    "    \"\"\"\n",
    "    ret = math.floor(sum(elo_ratings)/len(elo_ratings))\n",
    "    if ret < 0 or ret > 3386:\n",
    "        return -1\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    \"\"\"\n",
    "    # TODO: Add documentation\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    path = os.getcwd() + '\\\\DataCollection\\\\data\\\\'\n",
    "    matches = os.listdir(path)\n",
    "    for file_name in matches:\n",
    "        try:\n",
    "            with open(path + file_name) as f:\n",
    "                raw_data = json.load(f)\n",
    "                if raw_data['timeline'] and raw_data['elo'] and len(raw_data['timeline']) >= 15:\n",
    "                    avg_mmr = calculate_avg_mmr(raw_data['elo'])\n",
    "                    if avg_mmr != -1:\n",
    "                        x = torch.tensor(raw_data['timeline'][:15]) # only take the first 15 minutes\n",
    "                        data.append((x, avg_mmr))\n",
    "        except:\n",
    "            print(file_name + \" failed\")\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "def split_data(data, n_train=600, n_valid=0, n_test=0): # TODO: change values\n",
    "    return data[:n_train], data[n_train:], []\n",
    "\n",
    "\n",
    "def data_summary(data):\n",
    "    data_len = len(data)\n",
    "    one_dim = data[0][0].size()\n",
    "    \n",
    "    s = \"-- Data Summary --\" + \\\n",
    "        \"\\nNo. of datapoints = \" + str(data_len) + \\\n",
    "        \"\\nSingle datapoint shape = \" + str(one_dim)\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3bade4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.zip failed\n",
      "data2.zip failed\n",
      "data3.zip failed\n",
      "data4.zip failed\n"
     ]
    }
   ],
   "source": [
    "data = process_data()\n",
    "train_data, valid_data, test_data = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c93d24da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Data Summary --\n",
      "No. of datapoints = 1\n",
      "Single datapoint shape = torch.Size([15, 50])\n"
     ]
    }
   ],
   "source": [
    "print(data_summary(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc7ae3",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e3f279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=30, num_classes=27):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a4fce1",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8157b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(iters, losses, train_acc):\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, losses, label=\"Loss\")\n",
    "    plt.plot(iters, train_acc, label=\"Accuracy\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend([\"Loss\", \"Accuracy\"])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def classify_elo(elo):\n",
    "    \"\"\"\n",
    "    Return the index representing a ranking system in League of Legends.\n",
    "    \n",
    "    Iron IV, III, II, I = 0, 1, 2, 3\n",
    "    Bronze IV, III, II, I = 4, 5, 6, 7\n",
    "    Silver IV, III, II, I = 8, 9, 10, 11\n",
    "    Gold IV, III, II, I = 12, 13, 14, 15\n",
    "    Platinum IV, III, II, I = 16, 17, 18, 19\n",
    "    Diamond IV, III, II, I = 20, 21, 22, 23\n",
    "    Master = 24\n",
    "    Grandmaster = 25\n",
    "    Challengers = 26\n",
    "    \"\"\"\n",
    "    mmr_ranges = [\n",
    "        [0, 112], [112, 227], [227, 479], [497, 579], # Iron\n",
    "        [579, 757], [757, 963], [963, 1094], [1094, 1207], # Bronze\n",
    "        [1207, 1308], [1308, 1418], [1418, 1528], [1528, 1619], # Silver\n",
    "        [1619, 1702], [1702, 1793], [1793, 1896], [1896, 1980], # Gold\n",
    "        [1980, 2045], [2045, 2146], [2146, 2255], [2255, 2329], # Platinum\n",
    "        [2329, 2396], [2396, 2487], [2487, 2602], [2602, 2729], # Diamond\n",
    "        [2729, 2893], # Master\n",
    "        [2893, 3126], # Grandmaster \n",
    "        [3126, 3386] # Challenger\n",
    "    ]\n",
    "    for i in range(len(mmr_ranges)):\n",
    "        if mmr_ranges[i][0] <= elo < mmr_ranges[i][1]:\n",
    "            return i\n",
    "    \n",
    "    return -1 \n",
    "\n",
    "\n",
    "def get_accuracy(model, data):\n",
    "    \"\"\"\n",
    "    #TODO: brief explanation on what correct prediction is\n",
    "    \"\"\"\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=256, shuffle=True)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for matches, avg_mmrs in loader:\n",
    "        generated_mmr = model(match)\n",
    "        for i in range(len(avg_mmrs)):\n",
    "            if classify_elo(generated_mmr[i]) == classify_elo(avg_mmrs[i]):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    return correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "00720053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_data, valid_data=None, \\\n",
    "             batch_size=32, \\\n",
    "             weight_decay=0.0, \\\n",
    "             learning_rate=0.001, \\\n",
    "             num_epochs=7, \\\n",
    "             max_iters=1000, \\\n",
    "             checkpoint_path=None, \\\n",
    "             momentum=0.9, \\\n",
    "             save_after=100):\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "    \n",
    "    # We use Cross-Entropy Loss function and Adam optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "    n = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        tacc, vacc = 0, 0\n",
    "        for matches, avg_mmrs in iter(train_loader):\n",
    "            if matches.size()[0] < batch_size:\n",
    "                continue\n",
    "                \n",
    "            model.train()\n",
    "            output = model(matches) # forward pass\n",
    "            loss = criterion(output, avg_mmrs)\n",
    "            loss.backward() # backward pass\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            iters.append(n)\n",
    "            n += 1\n",
    "            losses.append(float(loss)/batch_size)\n",
    "            tacc = get_accuracy(model, train_data)\n",
    "            train_acc.append(tacc)\n",
    "            \n",
    "            if valid_data is not None:\n",
    "                vacc = get_accuracy(model, valid_data)\n",
    "                valid_acc.append(vacc)\n",
    "        \n",
    "        print(\"Epoch %d. [Train Acc %.0f%%] [Val Acc %.0f%%]\" % (epoch, tacc * 100, vac * 100))\n",
    "        torch.save(model.state_dict(), checkpoint_path.format(n))\n",
    "        \n",
    "    return iters, losses, train_acc, val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "563b2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(50)\n",
    "iters, losses, train_acc, val_acc = training(model, train_data, valid_data) # MODEL NOT FIXED YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(iters, losses, train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = get_accuracy(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- MMR Predictor Accuracy Results: --\")\n",
    "print(\"\\nTraining Accuracy: \", train_acc[-1])\n",
    "print(\"\\nValidation Accuracy: \", val_acc[-1])\n",
    "print(\"\\nTest Accuracy: \", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
